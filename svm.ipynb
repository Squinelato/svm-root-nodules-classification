{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from skimage.measure import moments_hu\n",
    "from mahotas.features import haralick\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identifier:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.features = None\n",
    "        self.labels = None\n",
    "        self.X_train = None  \n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        self.cross_val = StratifiedKFold(n_splits=5)\n",
    "        self.optimized_classifier = None\n",
    "\n",
    "    @staticmethod\n",
    "    def load_images_from_folder(folder):\n",
    "        images = list()\n",
    "        for filename in os.listdir(folder):\n",
    "            img = cv2.imread(os.path.join(folder, filename), cv2.IMREAD_GRAYSCALE)\n",
    "            if img is not None:\n",
    "                images.append(img)\n",
    "        return images\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_features(image):\n",
    "        return np.r_[moments_hu(image), haralick(image).flatten()]\n",
    "\n",
    "    def save_extracted_features(self, bboxes_path):\n",
    "        positive_instance = self.load_images_from_folder(bboxes_path + 'nodules/')\n",
    "        negative_instance = self.load_images_from_folder(bboxes_path + 'non-nodules/')\n",
    "\n",
    "        positive_features = np.array(list(map(self.extract_features, positive_instance)))\n",
    "        negative_features = np.array(list(map(self.extract_features, negative_instance)))\n",
    "\n",
    "        features = np.r_[positive_features, negative_features]\n",
    "        labels = np.r_[np.ones(len(positive_instance)), np.zeros(len(negative_instance))]\n",
    "\n",
    "        np.save('features/features.npy', features)\n",
    "        np.save('features/labels.npy', labels)\n",
    "\n",
    "    def load_features(self):\n",
    "        self.features = np.load('features/features.npy')\n",
    "        self.labels = np.load('features/labels.npy')\n",
    "        \n",
    "    def split_dataset(self):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.features, \n",
    "                                                            self.labels, \n",
    "                                                            stratify=self.labels, \n",
    "                                                            test_size=0.2)\n",
    "        self.X_train = X_train  \n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        \n",
    "    def normalize(self):\n",
    "        scaler = RobustScaler()\n",
    "        self.X_train = scaler.fit_transform(self.X_train)\n",
    "        self.X_test = scaler.transform(self.X_test)\n",
    "        \n",
    "    def training(self, kernel, scoring='f1_weighted'):\n",
    "        \n",
    "        if kernel != 'linear':\n",
    "            default_classifier = SVC(class_weight='balanced', \n",
    "                                     decision_function_shape='ovo', cache_size=4000)\n",
    "            \n",
    "            default_params = {'C': np.reciprocal(np.arange(1, 10).astype(np.float)), \n",
    "                              'kernel': [kernel], 'gamma': ['scale'],\n",
    "                              'coef0': np.arange(0, 10, 0.1), 'degree': range(1, 10)}\n",
    "        else:\n",
    "            n = self.X_train.shape[0]\n",
    "            default_classifier = SGDClassifier(loss='hinge',\n",
    "                                               class_weight='balanced', \n",
    "                                               max_iter = np.ceil(10**6 / n),\n",
    "                                               shuffle = True)\n",
    "            \n",
    "            default_params = {'alpha'    : 10.0**-np.arange(1,7),\n",
    "                              'l1_ratio' : np.arange(0.00, 1.001, 0.001)}\n",
    "\n",
    "\n",
    "        ran_search = GridSearchCV(default_classifier,\n",
    "                                  param_grid=default_params,\n",
    "                                  cv=self.cross_val, scoring=scoring,\n",
    "                                  verbose=3, n_jobs=4)\n",
    "\n",
    "        ran_search.fit(self.X_train, self.y_train)\n",
    "        print('Best score: {}'.format(ran_search.best_score_))\n",
    "        print('Best parameters: {}'.format(ran_search.best_params_))\n",
    "        \n",
    "        joblib.dump(ran_search.best_estimator_, 'classifiers/{}.plk'.format(kernel))\n",
    "        \n",
    "    def load_optimized_classifier(self, classifier_path):\n",
    "        self.optimized_classifier = joblib.load(classifier_path)\n",
    "        print('Parameters: {}'.format(self.optimized_classifier.get_params()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDENTIIER = Identifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDENTIIER.save_extracted_features('bbox_dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDENTIIER.load_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDENTIIER.split_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDENTIIER.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8100 candidates, totalling 40500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  40 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 2408 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=4)]: Done 7528 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=4)]: Done 14696 tasks      | elapsed:   26.4s\n",
      "[Parallel(n_jobs=4)]: Done 23912 tasks      | elapsed:   40.1s\n",
      "[Parallel(n_jobs=4)]: Done 35176 tasks      | elapsed:   57.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.7821123321123321\n",
      "Best parameters: {'C': 0.5, 'coef0': 0.9, 'degree': 3, 'gamma': 'scale', 'kernel': 'poly'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 40493 out of 40500 | elapsed:  1.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 40500 out of 40500 | elapsed:  1.1min finished\n"
     ]
    }
   ],
   "source": [
    "IDENTIIER.training('poly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'alpha': 0.001, 'average': False, 'class_weight': 'balanced', 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.0, 'fit_intercept': True, 'l1_ratio': 0.732, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 24391.0, 'n_iter_no_change': 5, 'n_jobs': None, 'penalty': 'l2', 'power_t': 0.5, 'random_state': None, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "IDENTIIER.load_optimized_classifier('classifiers/linear.plk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbasecondaec126aa0c77e42d49e9618db2a0d19bc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
